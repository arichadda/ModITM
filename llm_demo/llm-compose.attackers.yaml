version: '3.7'
services:
  # proxy:
  #   restart: always
  #   image: nginx:latest
  #   container_name: code_proxy
  #   build:
  #     context: attackers/evil_proxy
  #     dockerfile: Dockerfile
  #   image: 'moditm-llm-code_proxy:latest'
  #   cap_add:
  #     - NET_ADMIN
  #   volumes:
  #     - '${PWD}/attackers/evil_proxy/nginx.conf:/etc/nginx/nginx.conf'
  #     - '${PWD}/log:/var/log'
  #     - '${PWD}/pcaps:/pcaps'
  #   expose:
  #     - 11434
  #   ports:
  #     - 11438:11434
  #   healthcheck:
  #     test: curl --fail http://localhost:11434/api/tags || exit 1
  #     interval: 60s
  #     retries: 5
  #     start_period: 20s
  #     timeout: 10s
  #   networks:
  #     llm:
  #       ipv4_address: 192.168.2.16
  #   depends_on:
  #     evil_puller:
  #       condition: service_completed_successfully

  code_interceptor:
    container_name: code_interceptor
    hostname: code_interceptor
    restart: always
    build:
      context: attackers/code_interceptor
      dockerfile: Dockerfile
    image: 'moditm-code_interceptor:latest'
    cap_add:
      - NET_ADMIN
    environment:
      ORIGINAL_OLLAMA_HOST: '192.168.2.221'
      ORIGINAL_OLLAMA_PORT: 11434
      OLLAMA_HOST: '192.168.2.64'
      OLLAMA_PORT: 11434
    volumes:
      - '${PWD}/log:/var/log'
      - '${PWD}/config:/config'
      - '${PWD}/pcaps:/pcaps'
    expose:
      - 11434
    ports:
      - 11436:11434
    networks:
      llm:
        ipv4_address: 192.168.2.32
    stdin_open: true # docker run -i
    tty: true        # docker run -t

  badllama:
    container_name: badllama
    hostname: badllama
    restart: always
    build:
      context: codellama
      dockerfile: Dockerfile
    image: 'moditm-llm-codellama:latest'
    expose:
      - 11434
    ports:
      - 11437:11434
    volumes:
      - '${PWD}/badllama:/root/.ollama'
      - '${PWD}/pcaps:/pcaps'
    command: serve 
    healthcheck:
      test: curl --fail http://localhost:11434/api/tags || exit 1
      interval: 30s
      retries: 2
      start_period: 20s
      timeout: 2s
    networks:
      llm:
        ipv4_address: 192.168.2.64
    
  # evil_puller:
  #   image: 'curlimages/curl:8.6.0'
  #   environment:
  #     OLLAMA_HOST: 'badllama'
  #     OLLAMA_PORT: 11434
  #   volumes:
  #     - '${PWD}/attackers/model_puller:/model_puller'
  #   command: "/model_puller/pull.sh"
  #   networks:
  #     - llm
  #   depends_on:
  #     badllama:
  #       condition: service_healthy
networks:
  llm:
    name: llm
    external: true